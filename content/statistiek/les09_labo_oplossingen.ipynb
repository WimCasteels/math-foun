{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 9: Labo - Oplossingen\n",
    "\n",
    "**Mathematical Foundations - IT & Artificial Intelligence**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 1: Verwachtingswaarde - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 1a\n",
    "\n",
    "# 1. Discrete verdeling\n",
    "x1 = np.array([1, 2, 3])\n",
    "p1 = np.array([0.2, 0.5, 0.3])\n",
    "E_X1 = np.sum(x1 * p1)\n",
    "print(f\"1. E[X] = {E_X1}\")\n",
    "\n",
    "# 2. Binomiaal(n=10, p=0.3)\n",
    "# E[X] = n*p\n",
    "n, p = 10, 0.3\n",
    "E_X2 = n * p\n",
    "print(f\"2. E[Y] (Binomiaal) = n*p = {E_X2}\")\n",
    "\n",
    "# 3. Poisson(λ=5)\n",
    "# E[X] = λ\n",
    "lam = 5\n",
    "E_X3 = lam\n",
    "print(f\"3. E[Z] (Poisson) = λ = {E_X3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 1b - E[X²] vs (E[X])²\n",
    "E_X = np.sum(x1 * p1)\n",
    "E_X2_func = np.sum(x1**2 * p1)\n",
    "\n",
    "print(f\"E[X] = {E_X}\")\n",
    "print(f\"E[X²] = {E_X2_func}\")\n",
    "print(f\"(E[X])² = {E_X**2}\")\n",
    "print(f\"\\nE[X²] ≠ (E[X])² in het algemeen!\")\n",
    "print(f\"Het verschil is Var(X) = E[X²] - (E[X])² = {E_X2_func - E_X**2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 2: Variantie - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 2a\n",
    "\n",
    "# 1. Discrete verdeling\n",
    "E_X = np.sum(x1 * p1)\n",
    "E_X2 = np.sum(x1**2 * p1)\n",
    "Var_X1 = E_X2 - E_X**2\n",
    "print(f\"1. Var(X) = {Var_X1}\")\n",
    "\n",
    "# 2. Binomiaal(n=10, p=0.3)\n",
    "# Var(X) = n*p*(1-p)\n",
    "Var_X2 = n * p * (1 - p)\n",
    "print(f\"2. Var(Y) (Binomiaal) = n*p*(1-p) = {Var_X2}\")\n",
    "\n",
    "# 3. Poisson(λ=5)\n",
    "# Var(X) = λ\n",
    "Var_X3 = lam\n",
    "print(f\"3. Var(Z) (Poisson) = λ = {Var_X3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 2b - Var(aX + b) = a²·Var(X)\n",
    "X = np.random.normal(5, 2, 100000)  # Var = 4\n",
    "a, b = 3, 10\n",
    "Y = a * X + b\n",
    "\n",
    "print(f\"Var(X) = {np.var(X):.4f}\")\n",
    "print(f\"Var(aX + b) = Var({a}X + {b}) = {np.var(Y):.4f}\")\n",
    "print(f\"a² · Var(X) = {a**2} · {np.var(X):.4f} = {a**2 * np.var(X):.4f}\")\n",
    "print(f\"\\nDe constante b heeft geen effect op de variantie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 3: Steekproefgemiddelde - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 3a\n",
    "def sample_mean(x):\n",
    "    \"\"\"Bereken het steekproefgemiddelde.\"\"\"\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "def sample_variance(x, ddof=1):\n",
    "    \"\"\"Bereken de steekproefvariantie met Bessel's correctie.\"\"\"\n",
    "    n = len(x)\n",
    "    mean = sample_mean(x)\n",
    "    return np.sum((x - mean)**2) / (n - ddof)\n",
    "\n",
    "# Test\n",
    "data = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n",
    "print(f\"Data: {data}\")\n",
    "print(f\"Sample mean: {sample_mean(data)} (np: {np.mean(data)})\")\n",
    "print(f\"Sample variance (ddof=1): {sample_variance(data, 1):.4f} (np: {np.var(data, ddof=1):.4f})\")\n",
    "print(f\"Sample variance (ddof=0): {sample_variance(data, 0):.4f} (np: {np.var(data, ddof=0):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 3b - Bias van steekproefvariantie\n",
    "n_samples = 5\n",
    "n_experiments = 10000\n",
    "true_variance = 1.0  # N(0, 1)\n",
    "\n",
    "var_biased = []    # ddof=0\n",
    "var_unbiased = []  # ddof=1\n",
    "\n",
    "for _ in range(n_experiments):\n",
    "    sample = np.random.randn(n_samples)\n",
    "    var_biased.append(np.var(sample, ddof=0))\n",
    "    var_unbiased.append(np.var(sample, ddof=1))\n",
    "\n",
    "print(f\"True variance: {true_variance}\")\n",
    "print(f\"Mean of biased (N): {np.mean(var_biased):.4f}\")\n",
    "print(f\"Mean of unbiased (N-1): {np.mean(var_unbiased):.4f}\")\n",
    "print(f\"\\nBessel's correctie (N-1) geeft een onvertekende schatter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 4: Covariantie en Correlatie - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4a\n",
    "def covariance(x, y):\n",
    "    \"\"\"Bereken de steekproef-covariantie.\"\"\"\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    return np.sum((x - x_mean) * (y - y_mean)) / (n - 1)\n",
    "\n",
    "def correlation(x, y):\n",
    "    \"\"\"Bereken de Pearson correlatie.\"\"\"\n",
    "    cov = covariance(x, y)\n",
    "    std_x = np.std(x, ddof=1)\n",
    "    std_y = np.std(y, ddof=1)\n",
    "    return cov / (std_x * std_y)\n",
    "\n",
    "# Test\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "print(f\"Covariance: {covariance(x, y):.4f} (np: {np.cov(x, y)[0,1]:.4f})\")\n",
    "print(f\"Correlation: {correlation(x, y):.4f} (np: {np.corrcoef(x, y)[0,1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4b - Visualiseer correlaties\n",
    "def generate_correlated(n, rho):\n",
    "    \"\"\"Genereer data met gegeven correlatie.\"\"\"\n",
    "    x = np.random.randn(n)\n",
    "    z = np.random.randn(n)\n",
    "    y = rho * x + np.sqrt(1 - rho**2) * z\n",
    "    return x, y\n",
    "\n",
    "correlations = [0.9, 0.5, 0, -0.7]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for ax, rho in zip(axes.flatten(), correlations):\n",
    "    x, y = generate_correlated(200, rho)\n",
    "    actual_corr = np.corrcoef(x, y)[0, 1]\n",
    "    \n",
    "    ax.scatter(x, y, alpha=0.5)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(f'Target ρ = {rho}, Actual = {actual_corr:.3f}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 5: Batch Normalization - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5a\n",
    "class BatchNorm:\n",
    "    def __init__(self, n_features, epsilon=1e-5, momentum=0.9):\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.gamma = np.ones(n_features)\n",
    "        self.beta = np.zeros(n_features)\n",
    "        \n",
    "        self.running_mean = np.zeros(n_features)\n",
    "        self.running_var = np.ones(n_features)\n",
    "    \n",
    "    def forward(self, x, training=True):\n",
    "        if training:\n",
    "            self.mu = np.mean(x, axis=0)\n",
    "            self.var = np.var(x, axis=0)\n",
    "            \n",
    "            # Update running statistics\n",
    "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * self.mu\n",
    "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * self.var\n",
    "        else:\n",
    "            self.mu = self.running_mean\n",
    "            self.var = self.running_var\n",
    "        \n",
    "        self.x_centered = x - self.mu\n",
    "        self.std = np.sqrt(self.var + self.epsilon)\n",
    "        self.x_norm = self.x_centered / self.std\n",
    "        \n",
    "        out = self.gamma * self.x_norm + self.beta\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N = dout.shape[0]\n",
    "        \n",
    "        # Gradients for gamma and beta\n",
    "        self.dgamma = np.sum(dout * self.x_norm, axis=0)\n",
    "        self.dbeta = np.sum(dout, axis=0)\n",
    "        \n",
    "        # Gradient for x\n",
    "        dx_norm = dout * self.gamma\n",
    "        dvar = np.sum(dx_norm * self.x_centered * -0.5 * (self.var + self.epsilon)**(-1.5), axis=0)\n",
    "        dmu = np.sum(dx_norm * -1 / self.std, axis=0) + dvar * np.mean(-2 * self.x_centered, axis=0)\n",
    "        dx = dx_norm / self.std + dvar * 2 * self.x_centered / N + dmu / N\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5b - Test BatchNorm\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(64, 4) * 100 + 500  # Extreem gemiddelde en variantie\n",
    "\n",
    "bn = BatchNorm(4)\n",
    "out = bn.forward(x)\n",
    "\n",
    "print(\"Vóór BatchNorm:\")\n",
    "print(f\"  Mean: {np.mean(x, axis=0)}\")\n",
    "print(f\"  Var: {np.var(x, axis=0)}\")\n",
    "\n",
    "print(\"\\nNa BatchNorm:\")\n",
    "print(f\"  Mean: {np.mean(out, axis=0)}\")\n",
    "print(f\"  Var: {np.var(out, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 6: Weight Initialisatie - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 6a\n",
    "def xavier_init(n_in, n_out):\n",
    "    \"\"\"Xavier initialisatie.\"\"\"\n",
    "    std = np.sqrt(2.0 / (n_in + n_out))\n",
    "    return np.random.randn(n_in, n_out) * std\n",
    "\n",
    "def he_init(n_in, n_out):\n",
    "    \"\"\"He initialisatie.\"\"\"\n",
    "    std = np.sqrt(2.0 / n_in)\n",
    "    return np.random.randn(n_in, n_out) * std\n",
    "\n",
    "# Test\n",
    "W_xavier = xavier_init(256, 256)\n",
    "W_he = he_init(256, 256)\n",
    "\n",
    "print(f\"Xavier: mean={np.mean(W_xavier):.4f}, var={np.var(W_xavier):.6f}\")\n",
    "print(f\"He: mean={np.mean(W_he):.4f}, var={np.var(W_he):.6f}\")\n",
    "print(f\"\\nTheoretisch: Xavier var = 2/(256+256) = {2/512:.6f}\")\n",
    "print(f\"Theoretisch: He var = 2/256 = {2/256:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 6b\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "n_layers = 10\n",
    "n_neurons = 256\n",
    "batch_size = 100\n",
    "\n",
    "x = np.random.randn(batch_size, n_neurons)\n",
    "\n",
    "# Drie initialisaties\n",
    "inits = {\n",
    "    'N(0,1)': lambda n_in, n_out: np.random.randn(n_in, n_out),\n",
    "    'N(0,0.01)': lambda n_in, n_out: np.random.randn(n_in, n_out) * 0.01,\n",
    "    'He': he_init\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, init_fn in inits.items():\n",
    "    np.random.seed(42)\n",
    "    weights = [init_fn(n_neurons, n_neurons) for _ in range(n_layers)]\n",
    "    \n",
    "    variances = [np.var(x)]\n",
    "    h = x\n",
    "    for W in weights:\n",
    "        h = relu(h @ W)\n",
    "        variances.append(np.var(h))\n",
    "    \n",
    "    results[name] = variances\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, variances in results.items():\n",
    "    plt.plot(variances, 'o-', label=name)\n",
    "\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Activation Variance per Layer')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 7: Standaardisatie - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 7a\n",
    "class StandardScaler:\n",
    "    def fit(self, X):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.std_\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def inverse_transform(self, Z):\n",
    "        return Z * self.std_ + self.mean_\n",
    "\n",
    "# Test\n",
    "X = np.random.randn(100, 3) * np.array([10, 100, 1000]) + np.array([5, 50, 500])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Originele data:\")\n",
    "print(f\"  Mean: {np.mean(X, axis=0)}\")\n",
    "print(f\"  Std: {np.std(X, axis=0)}\")\n",
    "\n",
    "print(\"\\nGestandaardiseerde data:\")\n",
    "print(f\"  Mean: {np.mean(X_scaled, axis=0)}\")\n",
    "print(f\"  Std: {np.std(X_scaled, axis=0)}\")\n",
    "\n",
    "# Verify inverse\n",
    "X_recovered = scaler.inverse_transform(X_scaled)\n",
    "print(f\"\\nInverse transform correct: {np.allclose(X, X_recovered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 8: Wet van Grote Aantallen - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 8a\n",
    "lam = 2  # E[X] = 1/λ = 0.5\n",
    "true_mean = 1 / lam\n",
    "\n",
    "n_samples = 10000\n",
    "samples = np.random.exponential(1/lam, n_samples)\n",
    "\n",
    "# Cumulatief gemiddelde\n",
    "cumulative_mean = np.cumsum(samples) / np.arange(1, n_samples + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(cumulative_mean, 'b-', alpha=0.7)\n",
    "plt.axhline(y=true_mean, color='r', linestyle='--', linewidth=2, label=f'E[X] = {true_mean}')\n",
    "plt.xlabel('Aantal samples', fontsize=12)\n",
    "plt.ylabel('Cumulatief gemiddelde', fontsize=12)\n",
    "plt.title('Wet van Grote Aantallen: convergentie naar E[X]', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"True mean: {true_mean}\")\n",
    "print(f\"Sample mean (n={n_samples}): {np.mean(samples):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonusoefening: Variance Reduction - Oplossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antithetic variates voor E[e^U] waar U ~ Uniform(0,1)\n",
    "# True value: E[e^U] = e - 1 ≈ 1.7183\n",
    "\n",
    "true_value = np.e - 1\n",
    "n_experiments = 1000\n",
    "n_samples = 100\n",
    "\n",
    "# Standaard Monte Carlo\n",
    "estimates_standard = []\n",
    "for _ in range(n_experiments):\n",
    "    U = np.random.uniform(0, 1, n_samples)\n",
    "    estimates_standard.append(np.mean(np.exp(U)))\n",
    "\n",
    "# Antithetic variates\n",
    "estimates_antithetic = []\n",
    "for _ in range(n_experiments):\n",
    "    U = np.random.uniform(0, 1, n_samples // 2)\n",
    "    # Gebruik zowel U als 1-U\n",
    "    estimates_antithetic.append(np.mean((np.exp(U) + np.exp(1-U)) / 2))\n",
    "\n",
    "print(f\"True value: {true_value:.4f}\")\n",
    "print(f\"\\nStandard MC:\")\n",
    "print(f\"  Mean estimate: {np.mean(estimates_standard):.4f}\")\n",
    "print(f\"  Variance: {np.var(estimates_standard):.6f}\")\n",
    "print(f\"\\nAntithetic variates:\")\n",
    "print(f\"  Mean estimate: {np.mean(estimates_antithetic):.4f}\")\n",
    "print(f\"  Variance: {np.var(estimates_antithetic):.6f}\")\n",
    "print(f\"\\nVariance reduction: {np.var(estimates_standard)/np.var(estimates_antithetic):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Mathematical Foundations** | Les 9 Oplossingen | IT & Artificial Intelligence\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
