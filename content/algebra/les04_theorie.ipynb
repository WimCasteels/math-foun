{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 4: Stelsels en de Inverse Matrix\n",
    "\n",
    "**Mathematical Foundations - IT & Artificial Intelligence**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Recap en Motivatie\n",
    "\n",
    "In de vorige les hebben we gezien hoe matrices vectoren transformeren. Een matrix A transformeert vector x naar vector y via y = Ax. Nu stellen we de omgekeerde vraag: als we y kennen en A kennen, kunnen we dan x terugvinden?\n",
    "\n",
    "Dit is het probleem van het oplossen van een stelsel van lineaire vergelijkingen, een van de oudste en belangrijkste problemen in de wiskunde. Het heeft toepassingen in bijna elk wetenschappelijk domein, van natuurkunde tot economie tot machine learning.\n",
    "\n",
    "In machine learning is dit concept direct relevant. Linear regression is essentieel het oplossen van een stelsel vergelijkingen om de beste parameters te vinden. Het begrip van wanneer een stelsel wel of geen oplossing heeft, helpt ons begrijpen wanneer modellen kunnen falen. De pseudo-inverse, die we aan het eind van deze les introduceren, is de basis van veel optimalisatietechnieken.\n",
    "\n",
    "Dit is de laatste les van ons lineaire algebra blok. Na vandaag hebben we alle tools om te begrijpen hoe data door een neuraal netwerk stroomt. In les 5 beginnen we met calculus, waar we leren hoe een netwerk daadwerkelijk leert via gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Leerdoelen\n",
    "\n",
    "Na deze les kun je een stelsel van lineaire vergelijkingen voorstellen als een matrixvergelijking Ax = b. Je begrijpt wat de inverse van een matrix is en wanneer deze bestaat. Je kunt de determinant berekenen en interpreteren. Je kunt stelsels oplossen met NumPy en begrijpt wanneer er geen unieke oplossing is. Tot slot begrijp je de basis van lineaire regressie als het oplossen van een stelsel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer de benodigde libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Stelsels van Lineaire Vergelijkingen\n",
    "\n",
    "### Van vergelijkingen naar matrices\n",
    "\n",
    "Een lineair stelsel is een verzameling van lineaire vergelijkingen met dezelfde onbekenden. Een eenvoudig voorbeeld met twee vergelijkingen en twee onbekenden is:\n",
    "\n",
    "2x + 3y = 8\n",
    "\n",
    "x + 2y = 5\n",
    "\n",
    "We zoeken de waarden van x en y die beide vergelijkingen tegelijk waar maken. Dit stelsel kunnen we schrijven in matrixnotatie als Ax = b, waarbij A de coëfficiëntenmatrix is, x de vector van onbekenden, en b de vector van constanten aan de rechterkant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het stelsel in matrixnotatie\n",
    "# 2x + 3y = 8\n",
    "# 1x + 2y = 5\n",
    "\n",
    "A = np.array([[2, 3],\n",
    "              [1, 2]])\n",
    "\n",
    "b = np.array([8, 5])\n",
    "\n",
    "print(\"Stelsel van vergelijkingen:\")\n",
    "print(\"  2x + 3y = 8\")\n",
    "print(\"  1x + 2y = 5\")\n",
    "print()\n",
    "print(\"In matrixvorm Ax = b:\")\n",
    "print(f\"A = \\n{A}\")\n",
    "print(f\"b = {b}\")\n",
    "print()\n",
    "print(\"We zoeken x = [x, y] zodat A @ x = b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometrische interpretatie\n",
    "\n",
    "Elke lineaire vergelijking in twee variabelen beschrijft een rechte lijn in het vlak. De oplossing van het stelsel is het punt waar beide lijnen elkaar snijden. Als de lijnen parallel zijn, is er geen snijpunt en dus geen oplossing. Als de lijnen samenvallen, zijn er oneindig veel oplossingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiseer het stelsel als twee lijnen\n",
    "x_range = np.linspace(-1, 5, 100)\n",
    "\n",
    "# Lijn 1: 2x + 3y = 8 → y = (8 - 2x) / 3\n",
    "y1 = (8 - 2*x_range) / 3\n",
    "\n",
    "# Lijn 2: x + 2y = 5 → y = (5 - x) / 2\n",
    "y2 = (5 - x_range) / 2\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_range, y1, 'b-', linewidth=2, label='2x + 3y = 8')\n",
    "plt.plot(x_range, y2, 'r-', linewidth=2, label='x + 2y = 5')\n",
    "\n",
    "# De oplossing (we berekenen deze later)\n",
    "x_sol = np.linalg.solve(A, b)\n",
    "plt.plot(x_sol[0], x_sol[1], 'go', markersize=15, label=f'Oplossing ({x_sol[0]:.1f}, {x_sol[1]:.1f})')\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1, 5)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Stelsel van 2 vergelijkingen: snijpunt van 2 lijnen', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Het snijpunt is de oplossing: x = {x_sol[0]}, y = {x_sol[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oplossen met NumPy\n",
    "\n",
    "NumPy biedt de functie `np.linalg.solve(A, b)` om stelsels efficiënt op te lossen. Deze functie is numeriek stabieler en sneller dan het berekenen van de inverse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oplossen met NumPy\n",
    "x_oplossing = np.linalg.solve(A, b)\n",
    "\n",
    "print(f\"Oplossing: x = {x_oplossing}\")\n",
    "print(f\"  x = {x_oplossing[0]}\")\n",
    "print(f\"  y = {x_oplossing[1]}\")\n",
    "print()\n",
    "\n",
    "# Verificatie\n",
    "print(\"Verificatie (A @ x moet gelijk zijn aan b):\")\n",
    "print(f\"  A @ x = {A @ x_oplossing}\")\n",
    "print(f\"  b     = {b}\")\n",
    "print(f\"  Gelijk? {np.allclose(A @ x_oplossing, b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grotere stelsels\n",
    "\n",
    "De matrixnotatie schaalt elegant naar grotere stelsels. Een stelsel met 3 vergelijkingen en 3 onbekenden beschrijft drie vlakken in 3D-ruimte, en de oplossing is het punt waar alle drie de vlakken elkaar snijden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een groter stelsel: 3 vergelijkingen, 3 onbekenden\n",
    "# x + 2y + z = 9\n",
    "# 2x - y + 3z = 8\n",
    "# 3x + y - z = 3\n",
    "\n",
    "A3 = np.array([\n",
    "    [1, 2, 1],\n",
    "    [2, -1, 3],\n",
    "    [3, 1, -1]\n",
    "])\n",
    "\n",
    "b3 = np.array([9, 8, 3])\n",
    "\n",
    "x3 = np.linalg.solve(A3, b3)\n",
    "\n",
    "print(\"Stelsel:\")\n",
    "print(\"  x + 2y +  z = 9\")\n",
    "print(\" 2x -  y + 3z = 8\")\n",
    "print(\" 3x +  y -  z = 3\")\n",
    "print()\n",
    "print(f\"Oplossing: x = {x3[0]:.4f}, y = {x3[1]:.4f}, z = {x3[2]:.4f}\")\n",
    "print()\n",
    "print(f\"Verificatie: A @ x = {A3 @ x3}\")\n",
    "print(f\"            b     = {b3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 De Inverse Matrix\n",
    "\n",
    "### Definitie\n",
    "\n",
    "Voor gewone getallen geldt: als ax = b, dan x = b/a (mits a ≠ 0). Voor matrices kunnen we niet \"delen\", maar we kunnen iets vergelijkbaars doen met de inverse matrix.\n",
    "\n",
    "De inverse van een vierkante matrix A, genoteerd als A⁻¹, is de matrix waarvoor geldt: A × A⁻¹ = A⁻¹ × A = I, waarbij I de identiteitsmatrix is.\n",
    "\n",
    "Als A⁻¹ bestaat, kunnen we het stelsel Ax = b oplossen door beide zijden te vermenigvuldigen met A⁻¹: x = A⁻¹b. Dit is conceptueel elegant maar in de praktijk niet de beste manier om stelsels op te lossen vanwege numerieke stabiliteit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De inverse van matrix A\n",
    "A = np.array([[2, 3],\n",
    "              [1, 2]])\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "print(\"Inverse A⁻¹:\")\n",
    "print(A_inv)\n",
    "print()\n",
    "\n",
    "# Verificatie: A × A⁻¹ = I\n",
    "print(\"Verificatie: A @ A⁻¹ =\")\n",
    "print(A @ A_inv)\n",
    "print()\n",
    "print(\"Verificatie: A⁻¹ @ A =\")\n",
    "print(A_inv @ A)\n",
    "print()\n",
    "print(f\"Beide zijn de identiteitsmatrix? {np.allclose(A @ A_inv, np.eye(2)) and np.allclose(A_inv @ A, np.eye(2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stelsel oplossen met de inverse\n",
    "b = np.array([8, 5])\n",
    "\n",
    "# Methode 1: np.linalg.solve (aanbevolen)\n",
    "x_solve = np.linalg.solve(A, b)\n",
    "\n",
    "# Methode 2: via de inverse (minder efficiënt)\n",
    "x_inv = A_inv @ b\n",
    "\n",
    "print(\"Oplossing via np.linalg.solve:\", x_solve)\n",
    "print(\"Oplossing via inverse:         \", x_inv)\n",
    "print(f\"\\nZelfde resultaat? {np.allclose(x_solve, x_inv)}\")\n",
    "print()\n",
    "print(\"np.linalg.solve is efficiënter en numeriek stabieler.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De 2×2 inverse formule\n",
    "\n",
    "Voor een 2×2 matrix bestaat een eenvoudige formule voor de inverse. Als A = [[a, b], [c, d]], dan is:\n",
    "\n",
    "A⁻¹ = (1 / (ad - bc)) × [[d, -b], [-c, a]]\n",
    "\n",
    "De term (ad - bc) is de determinant van A, die we in de volgende sectie bespreken. Als deze nul is, bestaat de inverse niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2×2 inverse met de hand berekenen\n",
    "A = np.array([[2, 3],\n",
    "              [1, 2]])\n",
    "\n",
    "a, b = A[0, 0], A[0, 1]\n",
    "c, d = A[1, 0], A[1, 1]\n",
    "\n",
    "# Determinant\n",
    "det = a*d - b*c\n",
    "\n",
    "# Inverse volgens formule\n",
    "A_inv_manual = (1 / det) * np.array([[d, -b], \n",
    "                                      [-c, a]])\n",
    "\n",
    "print(f\"Matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "print(f\"Determinant: ad - bc = {a}×{d} - {b}×{c} = {det}\")\n",
    "print()\n",
    "print(\"Inverse (handmatig):\")\n",
    "print(A_inv_manual)\n",
    "print()\n",
    "print(\"Inverse (NumPy):\")\n",
    "print(np.linalg.inv(A))\n",
    "print()\n",
    "print(f\"Gelijk? {np.allclose(A_inv_manual, np.linalg.inv(A))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 De Determinant\n",
    "\n",
    "### Definitie en berekening\n",
    "\n",
    "De determinant is een getal dat bij elke vierkante matrix hoort. Voor een 2×2 matrix [[a, b], [c, d]] is de determinant eenvoudig: det(A) = ad - bc.\n",
    "\n",
    "Voor grotere matrices wordt de berekening complexer, maar NumPy handelt dit voor ons af met `np.linalg.det()`. De determinant heeft belangrijke eigenschappen die ons vertellen over het gedrag van de matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinant van een 2×2 matrix\n",
    "A = np.array([[3, 2],\n",
    "              [1, 4]])\n",
    "\n",
    "det_manual = A[0,0]*A[1,1] - A[0,1]*A[1,0]\n",
    "det_numpy = np.linalg.det(A)\n",
    "\n",
    "print(f\"Matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "print(f\"Determinant (handmatig): {A[0,0]}×{A[1,1]} - {A[0,1]}×{A[1,0]} = {det_manual}\")\n",
    "print(f\"Determinant (NumPy): {det_numpy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinant van een 3×3 matrix\n",
    "A3 = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "])\n",
    "\n",
    "print(f\"Matrix A:\")\n",
    "print(A3)\n",
    "print()\n",
    "print(f\"Determinant: {np.linalg.det(A3):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometrische betekenis\n",
    "\n",
    "De determinant heeft een mooie geometrische interpretatie: het is de schaalfactor voor oppervlakte (2D) of volume (3D) onder de lineaire transformatie.\n",
    "\n",
    "Als we een eenheidsvierkant transformeren met matrix A, dan is de oppervlakte van het resulterende parallellogram gelijk aan |det(A)|. Een negatieve determinant betekent dat de transformatie de oriëntatie omkeert (spiegeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometrische interpretatie van de determinant\n",
    "def visualize_determinant(A, title):\n",
    "    \"\"\"Visualiseer hoe een matrix het eenheidsvierkant transformeert.\"\"\"\n",
    "    # Eenheidsvierkant\n",
    "    square = np.array([[0, 1, 1, 0, 0],\n",
    "                       [0, 0, 1, 1, 0]])\n",
    "    \n",
    "    # Getransformeerd\n",
    "    transformed = A @ square\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Origineel\n",
    "    axes[0].fill(square[0], square[1], alpha=0.3, color='blue')\n",
    "    axes[0].plot(square[0], square[1], 'b-', linewidth=2)\n",
    "    axes[0].set_xlim(-0.5, 2.5)\n",
    "    axes[0].set_ylim(-1, 2.5)\n",
    "    axes[0].set_aspect('equal')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_title('Eenheidsvierkant\\nOppervlakte = 1', fontsize=12)\n",
    "    \n",
    "    # Getransformeerd\n",
    "    axes[1].fill(transformed[0], transformed[1], alpha=0.3, color='red')\n",
    "    axes[1].plot(transformed[0], transformed[1], 'r-', linewidth=2)\n",
    "    axes[1].set_xlim(-0.5, 2.5)\n",
    "    axes[1].set_ylim(-1, 2.5)\n",
    "    axes[1].set_aspect('equal')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    det = np.linalg.det(A)\n",
    "    axes[1].set_title(f'Getransformeerd\\nOppervlakte = |det(A)| = {abs(det):.2f}', fontsize=12)\n",
    "    \n",
    "    plt.suptitle(f'{title}\\ndet(A) = {det:.2f}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Schaling: vergroot de oppervlakte\n",
    "A_scale = np.array([[2, 0], [0, 1.5]])\n",
    "visualize_determinant(A_scale, 'Schaling')\n",
    "\n",
    "# Rotatie: behoudt de oppervlakte (det = 1)\n",
    "theta = np.pi/4\n",
    "A_rot = np.array([[np.cos(theta), -np.sin(theta)], \n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "visualize_determinant(A_rot, 'Rotatie (45°)')\n",
    "\n",
    "# Reflectie: negatieve determinant\n",
    "A_ref = np.array([[1, 0], [0, -1]])\n",
    "visualize_determinant(A_ref, 'Reflectie (over x-as)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant nul: singuliere matrices\n",
    "\n",
    "Wanneer de determinant nul is, heet de matrix singulier. Dit betekent dat de matrix geen inverse heeft en het stelsel Ax = b geen unieke oplossing heeft.\n",
    "\n",
    "Geometrisch betekent een determinant van nul dat de transformatie de ruimte \"platdrukt\" tot een lagere dimensie. Een 2D-vlak wordt bijvoorbeeld samengedrukt tot een lijn. Informatie gaat verloren en kan niet worden hersteld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singuliere matrix (determinant = 0)\n",
    "A_singular = np.array([[1, 2],\n",
    "                       [2, 4]])  # Rij 2 is 2× rij 1\n",
    "\n",
    "print(\"Singuliere matrix:\")\n",
    "print(A_singular)\n",
    "print()\n",
    "print(f\"Determinant: {np.linalg.det(A_singular):.10f}\")\n",
    "print()\n",
    "print(\"De rijen zijn lineair afhankelijk: rij 2 = 2 × rij 1\")\n",
    "print(\"Dit betekent dat beide vergelijkingen eigenlijk dezelfde lijn beschrijven.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wat gebeurt er als we proberen een singuliere matrix te inverteren?\n",
    "try:\n",
    "    A_inv = np.linalg.inv(A_singular)\n",
    "    print(\"Inverse berekend (dit zou niet moeten lukken)\")\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(f\"Fout: {e}\")\n",
    "    print(\"\\nDe inverse bestaat niet voor singuliere matrices!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiseer wat een singuliere matrix doet\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Maak een grid van punten\n",
    "x = np.linspace(-1, 1, 11)\n",
    "y = np.linspace(-1, 1, 11)\n",
    "X_grid, Y_grid = np.meshgrid(x, y)\n",
    "points = np.vstack([X_grid.ravel(), Y_grid.ravel()])\n",
    "\n",
    "# Transformeer met singuliere matrix\n",
    "A_singular = np.array([[1, 2], [0.5, 1]])\n",
    "print(f\"Determinant: {np.linalg.det(A_singular):.6f}\")\n",
    "transformed = A_singular @ points\n",
    "\n",
    "# Plot origineel\n",
    "axes[0].scatter(points[0], points[1], c='blue', alpha=0.5)\n",
    "axes[0].set_xlim(-3, 3)\n",
    "axes[0].set_ylim(-3, 3)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_title('Originele punten (2D grid)', fontsize=12)\n",
    "\n",
    "# Plot getransformeerd\n",
    "axes[1].scatter(transformed[0], transformed[1], c='red', alpha=0.5)\n",
    "axes[1].set_xlim(-3, 3)\n",
    "axes[1].set_ylim(-3, 3)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_title('Getransformeerd (samengedrukt tot lijn)', fontsize=12)\n",
    "\n",
    "plt.suptitle('Singuliere matrix: het 2D vlak wordt een 1D lijn', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAlle punten liggen nu op één lijn.\")\n",
    "print(\"We kunnen niet meer terug naar het originele grid - informatie is verloren.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Wanneer Heeft een Matrix een Inverse?\n",
    "\n",
    "Een matrix heeft een inverse als en alleen als aan de volgende (equivalente) voorwaarden is voldaan:\n",
    "\n",
    "De matrix moet vierkant zijn (evenveel rijen als kolommen). De determinant moet niet nul zijn. De rijen (of kolommen) moeten lineair onafhankelijk zijn. De matrix moet van volledige rang zijn.\n",
    "\n",
    "Als een van deze voorwaarden niet is vervuld, is de matrix singulier en bestaat er geen inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_matrix(A, name):\n",
    "    \"\"\"Analyseer of een matrix inverteerbaar is.\"\"\"\n",
    "    print(f\"Matrix {name}:\")\n",
    "    print(A)\n",
    "    print()\n",
    "    \n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        print(\"  ✗ Niet vierkant - geen inverse mogelijk\")\n",
    "        return\n",
    "    \n",
    "    det = np.linalg.det(A)\n",
    "    rank = np.linalg.matrix_rank(A)\n",
    "    \n",
    "    print(f\"  Determinant: {det:.6f}\")\n",
    "    print(f\"  Rang: {rank} (moet {A.shape[0]} zijn voor volledige rang)\")\n",
    "    \n",
    "    if abs(det) > 1e-10:\n",
    "        print(\"  ✓ Inverteerbaar!\")\n",
    "    else:\n",
    "        print(\"  ✗ Singulier - geen inverse\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Test verschillende matrices\n",
    "A1 = np.array([[2, 3], [1, 4]])\n",
    "analyze_matrix(A1, \"A1\")\n",
    "\n",
    "A2 = np.array([[1, 2], [2, 4]])\n",
    "analyze_matrix(A2, \"A2 (rijen zijn afhankelijk)\")\n",
    "\n",
    "A3 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "analyze_matrix(A3, \"A3 (identiteitsmatrix)\")\n",
    "\n",
    "A4 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "analyze_matrix(A4, \"A4 (rij 3 = rij 1 + rij 2 - 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Toepassing: Simpele Lineaire Regressie\n",
    "\n",
    "Lineaire regressie is een van de meest fundamentele technieken in machine learning, en het is in essentie het oplossen van een stelsel vergelijkingen.\n",
    "\n",
    "Stel we hebben datapunten (x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ) en we willen de beste rechte lijn y = ax + b vinden die door deze punten gaat. \"Beste\" betekent hier: de lijn die de som van kwadratische fouten minimaliseert.\n",
    "\n",
    "Dit leidt tot de normal equations: (XᵀX)w = Xᵀy, die we kunnen oplossen voor w = [b, a]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genereer wat voorbeeld data\n",
    "np.random.seed(42)\n",
    "n_points = 20\n",
    "\n",
    "# Echte relatie: y = 2x + 1 + noise\n",
    "x_data = np.linspace(0, 5, n_points)\n",
    "y_true = 2 * x_data + 1\n",
    "y_data = y_true + np.random.randn(n_points) * 0.5\n",
    "\n",
    "# Visualiseer de data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, s=50, c='blue', alpha=0.7, label='Data')\n",
    "plt.plot(x_data, y_true, 'g--', linewidth=2, alpha=0.5, label='Echte relatie (y = 2x + 1)')\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Data voor lineaire regressie', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire regressie via de normal equations\n",
    "# Model: y = b + a*x, of in matrixvorm: y = X @ w\n",
    "# waarbij X = [[1, x1], [1, x2], ...] en w = [b, a]\n",
    "\n",
    "# Design matrix\n",
    "X_design = np.column_stack([np.ones(n_points), x_data])\n",
    "\n",
    "print(\"Design matrix X (eerste 5 rijen):\")\n",
    "print(X_design[:5])\n",
    "print(f\"Shape: {X_design.shape}\")\n",
    "print()\n",
    "\n",
    "# Normal equations: (XᵀX)w = Xᵀy\n",
    "# Oplossing: w = (XᵀX)⁻¹ Xᵀy\n",
    "\n",
    "XtX = X_design.T @ X_design\n",
    "Xty = X_design.T @ y_data\n",
    "\n",
    "print(\"XᵀX:\")\n",
    "print(XtX)\n",
    "print()\n",
    "\n",
    "# Oplossen\n",
    "w = np.linalg.solve(XtX, Xty)\n",
    "\n",
    "print(f\"Oplossing: w = {w}\")\n",
    "print(f\"  Intercept (b): {w[0]:.4f}\")\n",
    "print(f\"  Slope (a): {w[1]:.4f}\")\n",
    "print()\n",
    "print(f\"Echte waarden: b = 1, a = 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiseer de fit\n",
    "y_predicted = X_design @ w\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, s=50, c='blue', alpha=0.7, label='Data')\n",
    "plt.plot(x_data, y_predicted, 'r-', linewidth=2, label=f'Fit: y = {w[0]:.2f} + {w[1]:.2f}x')\n",
    "plt.plot(x_data, y_true, 'g--', linewidth=2, alpha=0.5, label='Echte relatie')\n",
    "\n",
    "# Toon residuals\n",
    "for i in range(len(x_data)):\n",
    "    plt.plot([x_data[i], x_data[i]], [y_data[i], y_predicted[i]], 'r-', alpha=0.3)\n",
    "\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Lineaire regressie: de rode lijn minimaliseert de kwadratische fouten', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Bereken R²\n",
    "ss_res = np.sum((y_data - y_predicted) ** 2)\n",
    "ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "r_squared = 1 - ss_res / ss_tot\n",
    "\n",
    "print(f\"R² score: {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergelijk met sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_data.reshape(-1, 1), y_data)\n",
    "\n",
    "print(\"Vergelijking met sklearn:\")\n",
    "print(f\"  Onze implementatie: intercept = {w[0]:.6f}, slope = {w[1]:.6f}\")\n",
    "print(f\"  sklearn:            intercept = {model.intercept_:.6f}, slope = {model.coef_[0]:.6f}\")\n",
    "print()\n",
    "print(\"De resultaten zijn identiek!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 De Pseudo-inverse\n",
    "\n",
    "### Overgedetermineerde stelsels\n",
    "\n",
    "Vaak hebben we meer vergelijkingen dan onbekenden. Bij lineaire regressie hebben we bijvoorbeeld 20 datapunten maar slechts 2 parameters (intercept en slope). Zo'n systeem heet overgedetermineerd.\n",
    "\n",
    "Een overgedetermineerd systeem heeft meestal geen exacte oplossing, maar we kunnen wel de \"beste\" benadering vinden die de fout minimaliseert. Dit is precies wat de pseudo-inverse doet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De pseudo-inverse\n",
    "X_pinv = np.linalg.pinv(X_design)\n",
    "\n",
    "print(f\"Design matrix X: shape {X_design.shape}\")\n",
    "print(f\"Pseudo-inverse X⁺: shape {X_pinv.shape}\")\n",
    "print()\n",
    "\n",
    "# Oplossen met pseudo-inverse\n",
    "w_pinv = X_pinv @ y_data\n",
    "\n",
    "print(\"Oplossing via normal equations:\", w)\n",
    "print(\"Oplossing via pseudo-inverse:  \", w_pinv)\n",
    "print(f\"\\nGelijk? {np.allclose(w, w_pinv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.lstsq is de aanbevolen manier\n",
    "w_lstsq, residuals, rank, s = np.linalg.lstsq(X_design, y_data, rcond=None)\n",
    "\n",
    "print(\"np.linalg.lstsq resultaat:\")\n",
    "print(f\"  Parameters: {w_lstsq}\")\n",
    "print(f\"  Residuals (som van kwadraten): {residuals[0] if len(residuals) > 0 else 'N/A'}\")\n",
    "print(f\"  Rang: {rank}\")\n",
    "print()\n",
    "print(\"Dit is de meest robuuste manier om least-squares problemen op te lossen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wanneer de normale vergelijkingen falen\n",
    "\n",
    "De normal equations (XᵀX)w = Xᵀy werken alleen als XᵀX inverteerbaar is. Dit kan falen als de kolommen van X niet lineair onafhankelijk zijn (multicollineariteit). De pseudo-inverse en `np.linalg.lstsq` zijn robuuster in zulke gevallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorbeeld met multicollineariteit\n",
    "# Voeg een kolom toe die perfect gecorreleerd is\n",
    "X_bad = np.column_stack([np.ones(n_points), x_data, 2*x_data])  # Kolom 3 = 2 × kolom 2\n",
    "\n",
    "print(f\"Design matrix met multicollineariteit: shape {X_bad.shape}\")\n",
    "print()\n",
    "\n",
    "XtX_bad = X_bad.T @ X_bad\n",
    "print(f\"Determinant van XᵀX: {np.linalg.det(XtX_bad):.6e}\")\n",
    "print(\"(Bijna nul - numeriek singulier!)\")\n",
    "print()\n",
    "\n",
    "# lstsq werkt nog steeds\n",
    "w_bad, _, rank, _ = np.linalg.lstsq(X_bad, y_data, rcond=None)\n",
    "print(f\"lstsq oplossing: {w_bad}\")\n",
    "print(f\"Rang: {rank} (verwacht 2, niet 3 vanwege afhankelijkheid)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Samenvatting en Vooruitblik\n",
    "\n",
    "### Kernconcepten\n",
    "\n",
    "In deze les hebben we geleerd hoe stelsels van lineaire vergelijkingen worden voorgesteld in matrixnotatie als Ax = b. De inverse matrix A⁻¹ stelt ons in staat om de oplossing te vinden als x = A⁻¹b, maar alleen als A inverteerbaar is.\n",
    "\n",
    "De determinant is een getal dat aangeeft of een matrix inverteerbaar is (det ≠ 0) of singulier (det = 0). Geometrisch geeft de determinant de schaalfactor voor oppervlakte of volume weer.\n",
    "\n",
    "Voor praktische berekeningen gebruiken we `np.linalg.solve` voor vierkante systemen en `np.linalg.lstsq` voor overgedetermineerde systemen. De pseudo-inverse is een generalisatie van de inverse die ook werkt wanneer de gewone inverse niet bestaat.\n",
    "\n",
    "We hebben gezien dat lineaire regressie in essentie het oplossen van een stelsel is via de normal equations, wat de basis vormt van veel machine learning technieken.\n",
    "\n",
    "### Link naar het neurale netwerk\n",
    "\n",
    "Hoewel neurale netwerken niet direct gebruik maken van matrix-inversie (de optimalisatie gebeurt iteratief via gradient descent), is het begrip van wanneer systemen wel of niet oplosbaar zijn cruciaal. Het helpt ons begrijpen waarom bepaalde architecturen beter werken dan andere en wat er kan falen tijdens training.\n",
    "\n",
    "### Volgende les\n",
    "\n",
    "We hebben nu alle lineaire algebra die we nodig hebben! In les 5 beginnen we met calculus, specifiek afgeleiden. We leren hoe we de \"fout\" van het netwerk kunnen meten en hoe we deze fout kunnen verminderen door de gewichten aan te passen. Dit is het hart van hoe neurale netwerken leren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist\n",
    "\n",
    "Controleer of je de volgende concepten begrijpt:\n",
    "\n",
    "1. Hoe schrijf je een stelsel vergelijkingen in matrixvorm Ax = b?\n",
    "\n",
    "2. Wat is de inverse van een matrix en wanneer bestaat deze?\n",
    "\n",
    "3. Wat betekent een determinant van nul?\n",
    "\n",
    "4. Hoe los je een stelsel op met NumPy?\n",
    "\n",
    "5. Wat doet lineaire regressie wiskundig?\n",
    "\n",
    "Als je deze vragen kunt beantwoorden, ben je klaar voor het calculus-gedeelte van de cursus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Mathematical Foundations** | Les 4 van 12 | IT & Artificial Intelligence\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
