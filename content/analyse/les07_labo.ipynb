{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 7: Labo - Oefeningen\n",
    "\n",
    "**Mathematical Foundations - IT & Artificial Intelligence**\n",
    "\n",
    "---\n",
    "\n",
    "In dit labo implementeer je backpropagation en train je een neuraal netwerk op MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 1: Computational Graph Tekenen\n",
    "\n",
    "*Geschatte tijd: 10 minuten*\n",
    "\n",
    "### Opdracht 1a\n",
    "\n",
    "Teken de computational graph voor de volgende expressies. Identificeer alle tussenresultaten.\n",
    "\n",
    "1. f(x, y) = (x + y) * (x - y)\n",
    "2. g(x, w, b) = σ(wx + b) waar σ de sigmoid is\n",
    "3. h(x, W1, b1, W2, b2) = W2 @ ReLU(W1 @ x + b1) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jouw antwoord (teken of beschrijf de graphs):*\n",
    "\n",
    "1. f(x, y):\n",
    "\n",
    "2. g(x, w, b):\n",
    "\n",
    "3. h(x, W1, b1, W2, b2):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 2: Lokale Gradiënten\n",
    "\n",
    "*Geschatte tijd: 20 minuten*\n",
    "\n",
    "### Opdracht 2a\n",
    "\n",
    "Implementeer de volgende operaties met `forward` en `backward` methodes:\n",
    "\n",
    "1. **Add**: z = x + y\n",
    "2. **Multiply**: z = x * y\n",
    "3. **Power**: z = x^n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add:\n",
    "    def forward(self, x, y):\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # Return (dx, dy)\n",
    "        pass\n",
    "\n",
    "class Multiply:\n",
    "    def forward(self, x, y):\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # Return (dx, dy)\n",
    "        pass\n",
    "\n",
    "class Power:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # Return dx\n",
    "        pass\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 2b\n",
    "\n",
    "Implementeer de sigmoid en tanh activatiefuncties met forward en backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, x):\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, x):\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 3: Backprop met de Hand\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 3a\n",
    "\n",
    "Gegeven het volgende mini-netwerk en concrete waarden:\n",
    "\n",
    "```\n",
    "x = 2\n",
    "w1 = 0.5, b1 = 0.1\n",
    "w2 = -0.3, b2 = 0.2\n",
    "y_target = 0.5\n",
    "\n",
    "h = ReLU(w1*x + b1)\n",
    "y = sigmoid(w2*h + b2)\n",
    "L = (y - y_target)²\n",
    "```\n",
    "\n",
    "Bereken met de hand (en verifieer met code):\n",
    "1. Alle tussenresultaten in de forward pass\n",
    "2. ∂L/∂y, ∂L/∂h, ∂L/∂w2, ∂L/∂b2, ∂L/∂w1, ∂L/∂b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw uitwerking hier\n",
    "\n",
    "# Gegeven waarden\n",
    "x = 2\n",
    "w1, b1 = 0.5, 0.1\n",
    "w2, b2 = -0.3, 0.2\n",
    "y_target = 0.5\n",
    "\n",
    "# Forward pass\n",
    "# ...\n",
    "\n",
    "# Backward pass\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 4: Gradient Checking\n",
    "\n",
    "*Geschatte tijd: 15 minuten*\n",
    "\n",
    "### Opdracht 4a\n",
    "\n",
    "Implementeer een `gradient_check` functie die de analytische gradiënt vergelijkt met de numerieke gradiënt. De functie moet het relatieve verschil teruggeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(f, x, analytic_grad, h=1e-5):\n",
    "    \"\"\"\n",
    "    Vergelijk analytische gradiënt met numerieke gradiënt.\n",
    "    \n",
    "    Parameters:\n",
    "    - f: functie die een scalar teruggeeft\n",
    "    - x: punt waar we de gradiënt controleren\n",
    "    - analytic_grad: analytisch berekende gradiënt\n",
    "    - h: stapgrootte voor numerieke gradiënt\n",
    "    \n",
    "    Returns:\n",
    "    - relative_error: relatieve fout tussen beide gradiënten\n",
    "    \"\"\"\n",
    "    # Jouw code hier\n",
    "    pass\n",
    "\n",
    "# Test met f(x) = x²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 4b\n",
    "\n",
    "Gebruik gradient checking om te verifiëren dat je sigmoid backward implementatie correct is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 5: Layer Class met Backward\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 5a\n",
    "\n",
    "Implementeer een `LinearLayer` class met forward en backward methodes. De laag berekent: z = X @ W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Initialiseer W en b\n",
    "        # Jouw code hier\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X shape: (batch_size, input_dim)\n",
    "        # Return shape: (batch_size, output_dim)\n",
    "        # Sla X op voor backward!\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # dout shape: (batch_size, output_dim)\n",
    "        # Bereken self.dW en self.db\n",
    "        # Return dX shape: (batch_size, input_dim)\n",
    "        pass\n",
    "\n",
    "# Test\n",
    "layer = LinearLayer(3, 2)\n",
    "X = np.random.randn(4, 3)  # 4 samples, 3 features\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 5b\n",
    "\n",
    "Implementeer een `ReLULayer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer:\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 6: Mini-netwerk Trainen\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 6a\n",
    "\n",
    "Train een netwerk met 1 hidden layer op een XOR-achtig probleem:\n",
    "- Input: 2D punten\n",
    "- Output: 1 als punt in kwadrant 1 of 3, 0 anders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genereer XOR-achtige data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "X = np.random.randn(n_samples, 2)\n",
    "y = ((X[:, 0] > 0) == (X[:, 1] > 0)).astype(float)  # XOR-achtig\n",
    "\n",
    "# Visualiseer\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', label='Klasse 0')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='red', label='Klasse 1')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('XOR-achtig probleem')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bouw en train je netwerk\n",
    "# Jouw code hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 7: MNIST Trainen\n",
    "\n",
    "*Geschatte tijd: 30 minuten*\n",
    "\n",
    "### Opdracht 7a\n",
    "\n",
    "Train een neuraal netwerk op MNIST. Gebruik de layer classes die je hebt geïmplementeerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad MNIST\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "print(\"MNIST laden...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
    "\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "print(f\"Training: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax en Cross-Entropy (gegeven)\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(probs, y_true):\n",
    "    N = probs.shape[0]\n",
    "    return -np.sum(np.log(probs[np.arange(N), y_true] + 1e-10)) / N\n",
    "\n",
    "def cross_entropy_gradient(probs, y_true):\n",
    "    N = probs.shape[0]\n",
    "    grad = probs.copy()\n",
    "    grad[np.arange(N), y_true] -= 1\n",
    "    return grad / N\n",
    "\n",
    "# Jouw netwerk en training loop hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 7b\n",
    "\n",
    "Experimenteer met hyperparameters:\n",
    "- Probeer verschillende hidden layer sizes (64, 128, 256)\n",
    "- Probeer verschillende learning rates (0.1, 0.5, 1.0)\n",
    "- Wat geeft de beste test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw experimenten hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 8: Hyperparameter Experimenten\n",
    "\n",
    "*Geschatte tijd: 20 minuten*\n",
    "\n",
    "### Opdracht 8a\n",
    "\n",
    "Maak een systematische vergelijking van:\n",
    "1. Effect van batch size (16, 32, 64, 128)\n",
    "2. Effect van learning rate (0.01, 0.1, 0.5, 1.0)\n",
    "\n",
    "Plot de learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw experimenten hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonusoefening: Tweede Hidden Layer\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Bonus\n",
    "\n",
    "Breid je netwerk uit met een tweede hidden layer:\n",
    "784 → 256 → 128 → 10\n",
    "\n",
    "Train op MNIST en vergelijk de accuracy met het netwerk met 1 hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor de bonusoefening\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Klaar!\n",
    "\n",
    "Je hebt nu backpropagation geïmplementeerd en een neuraal netwerk getraind op MNIST! Dit is een belangrijke mijlpaal - je begrijpt nu wat er onder de motorkap van deep learning frameworks gebeurt.\n",
    "\n",
    "---\n",
    "\n",
    "**Mathematical Foundations** | Les 7 Labo | IT & Artificial Intelligence\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
