{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 5: Labo - Oplossingen\n",
    "\n",
    "**Mathematical Foundations - IT & Artificial Intelligence**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "print(\"Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 1: Numerieke Afgeleiden - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 1a\n",
    "def numerical_derivative(f, x, h=1e-5):\n",
    "    \"\"\"Forward difference methode.\"\"\"\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# Test\n",
    "def f_test(x):\n",
    "    return x**2\n",
    "\n",
    "print(f\"f(x) = x², f'(x) = 2x\")\n",
    "print(f\"f'(3) analytisch = 6\")\n",
    "print(f\"f'(3) numeriek = {numerical_derivative(f_test, 3):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 1b\n",
    "def f(x):\n",
    "    return x**3\n",
    "\n",
    "x = 2\n",
    "exact = 3 * x**2  # f'(x) = 3x²\n",
    "\n",
    "print(f\"f(x) = x³, f'(x) = 3x²\")\n",
    "print(f\"f'({x}) analytisch = {exact}\")\n",
    "print()\n",
    "print(f\"{'h':>12} | {'Numeriek':>15} | {'Fout':>15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for h in [1, 0.1, 0.01, 0.001, 1e-5, 1e-8, 1e-12]:\n",
    "    num = numerical_derivative(f, x, h)\n",
    "    error = abs(num - exact)\n",
    "    print(f\"{h:>12.2e} | {num:>15.10f} | {error:>15.2e}\")\n",
    "\n",
    "print()\n",
    "print(\"Observatie: voor zeer kleine h (< 1e-10) treedt numerieke instabiliteit op.\")\n",
    "print(\"Dit komt door afrondingsfouten in floating-point berekeningen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 1c\n",
    "def central_difference(f, x, h=1e-5):\n",
    "    \"\"\"Central difference methode - nauwkeuriger!\"\"\"\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "print(\"Vergelijking forward vs central difference:\")\n",
    "print(f\"{'h':>12} | {'Forward fout':>15} | {'Central fout':>15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for h in [0.1, 0.01, 0.001, 1e-5, 1e-8]:\n",
    "    fwd = numerical_derivative(f, x, h)\n",
    "    ctr = central_difference(f, x, h)\n",
    "    fwd_err = abs(fwd - exact)\n",
    "    ctr_err = abs(ctr - exact)\n",
    "    print(f\"{h:>12.2e} | {fwd_err:>15.2e} | {ctr_err:>15.2e}\")\n",
    "\n",
    "print()\n",
    "print(\"Central difference is veel nauwkeuriger voor dezelfde h!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 2: Basisregels Oefenen - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 2a\n",
    "print(\"Analytische afgeleiden:\")\n",
    "print(\"1. f(x) = 5x⁴     → f'(x) = 20x³\")\n",
    "print(\"2. g(x) = x³-2x²+4x-1 → g'(x) = 3x²-4x+4\")\n",
    "print(\"3. h(x) = 3/x = 3x⁻¹ → h'(x) = -3x⁻² = -3/x²\")\n",
    "print(\"4. k(x) = √x = x^(1/2) → k'(x) = (1/2)x^(-1/2) = 1/(2√x)\")\n",
    "print(\"5. m(x) = 2eˣ+3x² → m'(x) = 2eˣ+6x\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementaties en verificatie\n",
    "functions = [\n",
    "    (\"5x⁴\", lambda x: 5*x**4, lambda x: 20*x**3),\n",
    "    (\"x³-2x²+4x-1\", lambda x: x**3 - 2*x**2 + 4*x - 1, lambda x: 3*x**2 - 4*x + 4),\n",
    "    (\"3/x\", lambda x: 3/x, lambda x: -3/x**2),\n",
    "    (\"√x\", lambda x: np.sqrt(x), lambda x: 1/(2*np.sqrt(x))),\n",
    "    (\"2eˣ+3x²\", lambda x: 2*np.exp(x) + 3*x**2, lambda x: 2*np.exp(x) + 6*x),\n",
    "]\n",
    "\n",
    "x_test = 2.0  # Gebruik 2 om deling door 0 te vermijden\n",
    "\n",
    "print(f\"Verificatie op x = {x_test}:\")\n",
    "print(f\"{'Functie':>15} | {'Analytisch':>12} | {'Numeriek':>12} | {'OK?':>5}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name, f, f_prime in functions:\n",
    "    ana = f_prime(x_test)\n",
    "    num = numerical_derivative(f, x_test)\n",
    "    ok = \"✓\" if np.isclose(ana, num, rtol=1e-4) else \"✗\"\n",
    "    print(f\"{name:>15} | {ana:>12.6f} | {num:>12.6f} | {ok:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 2b\n",
    "def f(x):\n",
    "    return x**3 - 3*x + 1\n",
    "\n",
    "def f_prime(x):\n",
    "    return 3*x**2 - 3\n",
    "\n",
    "x_range = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_range, f(x_range), 'b-', linewidth=2, label='f(x) = x³ - 3x + 1')\n",
    "plt.plot(x_range, f_prime(x_range), 'r-', linewidth=2, label=\"f'(x) = 3x² - 3\")\n",
    "plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "# Markeer waar f'(x) = 0\n",
    "# 3x² - 3 = 0 → x² = 1 → x = ±1\n",
    "plt.plot([-1, 1], [f(-1), f(1)], 'go', markersize=10, label='Extrema (f\\'=0)')\n",
    "\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"f'(x) = 0 op x = ±1 (lokaal maximum en minimum)\", fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"f'(x) = 0 op x = -1 en x = 1\")\n",
    "print(f\"f(-1) = {f(-1)} (lokaal maximum)\")\n",
    "print(f\"f(1) = {f(1)} (lokaal minimum)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 3: De Kettingregel - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 3a\n",
    "print(\"Kettingregel: (f∘g)'(x) = f'(g(x)) · g'(x)\")\n",
    "print()\n",
    "print(\"1. f(x) = (2x+1)³\")\n",
    "print(\"   g(x) = 2x+1, f(u) = u³\")\n",
    "print(\"   f'(x) = 3(2x+1)² · 2 = 6(2x+1)²\")\n",
    "print()\n",
    "print(\"2. g(x) = e^(x²)\")\n",
    "print(\"   h(x) = x², f(u) = eᵘ\")\n",
    "print(\"   g'(x) = e^(x²) · 2x = 2x·e^(x²)\")\n",
    "print()\n",
    "print(\"3. h(x) = sin(3x)\")\n",
    "print(\"   u(x) = 3x, f(u) = sin(u)\")\n",
    "print(\"   h'(x) = cos(3x) · 3 = 3cos(3x)\")\n",
    "print()\n",
    "print(\"4. k(x) = √(x²+1)\")\n",
    "print(\"   u(x) = x²+1, f(u) = √u\")\n",
    "print(\"   k'(x) = 1/(2√(x²+1)) · 2x = x/√(x²+1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificatie\n",
    "functions_chain = [\n",
    "    (\"(2x+1)³\", lambda x: (2*x+1)**3, lambda x: 6*(2*x+1)**2),\n",
    "    (\"e^(x²)\", lambda x: np.exp(x**2), lambda x: 2*x*np.exp(x**2)),\n",
    "    (\"sin(3x)\", lambda x: np.sin(3*x), lambda x: 3*np.cos(3*x)),\n",
    "    (\"√(x²+1)\", lambda x: np.sqrt(x**2+1), lambda x: x/np.sqrt(x**2+1)),\n",
    "]\n",
    "\n",
    "x_test = 1.5\n",
    "\n",
    "print(f\"Verificatie op x = {x_test}:\")\n",
    "for name, f, f_prime in functions_chain:\n",
    "    ana = f_prime(x_test)\n",
    "    num = numerical_derivative(f, x_test)\n",
    "    print(f\"{name:>12}: analytisch = {ana:>10.6f}, numeriek = {num:>10.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 3b\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def f(x):\n",
    "    return sigmoid(2*x - 1)\n",
    "\n",
    "# Kettingregel: f'(x) = σ'(2x-1) · 2\n",
    "# σ'(u) = σ(u)(1-σ(u))\n",
    "def f_prime(x):\n",
    "    u = 2*x - 1\n",
    "    sig = sigmoid(u)\n",
    "    return sig * (1 - sig) * 2\n",
    "\n",
    "x_range = np.linspace(-2, 3, 100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(x_range, f(x_range), 'b-', linewidth=2)\n",
    "axes[0].set_title('f(x) = σ(2x - 1)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(x_range, f_prime(x_range), 'r-', linewidth=2)\n",
    "axes[1].set_title(\"f'(x) = 2σ(2x-1)(1-σ(2x-1))\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verificatie\n",
    "for x in [0, 0.5, 1]:\n",
    "    print(f\"x = {x}: f'(x) analytisch = {f_prime(x):.6f}, numeriek = {numerical_derivative(f, x):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 3c\n",
    "# f(x) = e^(sin(x²))\n",
    "# h(x) = x², g(u) = sin(u), f(v) = eᵛ\n",
    "# f'(x) = e^(sin(x²)) · cos(x²) · 2x\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(np.sin(x**2))\n",
    "\n",
    "def f_prime(x):\n",
    "    return np.exp(np.sin(x**2)) * np.cos(x**2) * 2*x\n",
    "\n",
    "x_test = 1.0\n",
    "print(\"f(x) = e^(sin(x²))\")\n",
    "print(\"f'(x) = e^(sin(x²)) · cos(x²) · 2x\")\n",
    "print()\n",
    "print(f\"x = {x_test}:\")\n",
    "print(f\"  f'(x) analytisch = {f_prime(x_test):.6f}\")\n",
    "print(f\"  f'(x) numeriek   = {numerical_derivative(f, x_test):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 4: Partiële Afgeleiden - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4a\n",
    "def numerical_partial_x(f, x, y, h=1e-5):\n",
    "    return (f(x + h, y) - f(x, y)) / h\n",
    "\n",
    "def numerical_partial_y(f, x, y, h=1e-5):\n",
    "    return (f(x, y + h) - f(x, y)) / h\n",
    "\n",
    "# 1. f(x,y) = x² + y²\n",
    "f1 = lambda x, y: x**2 + y**2\n",
    "df1_dx = lambda x, y: 2*x\n",
    "df1_dy = lambda x, y: 2*y\n",
    "\n",
    "# 2. f(x,y) = 3xy + x - 2y\n",
    "f2 = lambda x, y: 3*x*y + x - 2*y\n",
    "df2_dx = lambda x, y: 3*y + 1\n",
    "df2_dy = lambda x, y: 3*x - 2\n",
    "\n",
    "# 3. f(x,y) = e^(xy)\n",
    "f3 = lambda x, y: np.exp(x*y)\n",
    "df3_dx = lambda x, y: y * np.exp(x*y)\n",
    "df3_dy = lambda x, y: x * np.exp(x*y)\n",
    "\n",
    "# 4. f(x,y) = x²y³\n",
    "f4 = lambda x, y: x**2 * y**3\n",
    "df4_dx = lambda x, y: 2*x * y**3\n",
    "df4_dy = lambda x, y: x**2 * 3*y**2\n",
    "\n",
    "# Test\n",
    "x, y = 2.0, 3.0\n",
    "print(f\"Test op punt ({x}, {y}):\")\n",
    "print()\n",
    "\n",
    "funcs = [\n",
    "    (\"x²+y²\", f1, df1_dx, df1_dy),\n",
    "    (\"3xy+x-2y\", f2, df2_dx, df2_dy),\n",
    "    (\"e^(xy)\", f3, df3_dx, df3_dy),\n",
    "    (\"x²y³\", f4, df4_dx, df4_dy),\n",
    "]\n",
    "\n",
    "for name, f, dfdx, dfdy in funcs:\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ∂f/∂x: ana={dfdx(x,y):.4f}, num={numerical_partial_x(f,x,y):.4f}\")\n",
    "    print(f\"  ∂f/∂y: ana={dfdy(x,y):.4f}, num={numerical_partial_y(f,x,y):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 4b\n",
    "# f(x,y,z) = x²y + yz² + xz\n",
    "# ∂f/∂x = 2xy + z\n",
    "# ∂f/∂y = x² + z²\n",
    "# ∂f/∂z = 2yz + x\n",
    "\n",
    "def f(x, y, z):\n",
    "    return x**2 * y + y * z**2 + x * z\n",
    "\n",
    "def gradient_f(x, y, z):\n",
    "    df_dx = 2*x*y + z\n",
    "    df_dy = x**2 + z**2\n",
    "    df_dz = 2*y*z + x\n",
    "    return np.array([df_dx, df_dy, df_dz])\n",
    "\n",
    "# Evalueer op (1, 2, 3)\n",
    "x, y, z = 1, 2, 3\n",
    "\n",
    "print(f\"f(x,y,z) = x²y + yz² + xz\")\n",
    "print(f\"\\nOp punt ({x}, {y}, {z}):\")\n",
    "print(f\"  f = {f(x, y, z)}\")\n",
    "print()\n",
    "print(f\"∂f/∂x = 2xy + z = 2·{x}·{y} + {z} = {2*x*y + z}\")\n",
    "print(f\"∂f/∂y = x² + z² = {x}² + {z}² = {x**2 + z**2}\")\n",
    "print(f\"∂f/∂z = 2yz + x = 2·{y}·{z} + {x} = {2*y*z + x}\")\n",
    "print()\n",
    "print(f\"∇f = {gradient_f(x, y, z)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 5: Gradiënt Visualiseren - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5a - Paraboloïde\n",
    "x_range = np.linspace(-3, 3, 50)\n",
    "y_range = np.linspace(-3, 3, 50)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# Gradiënt op grove grid\n",
    "x_arr = np.linspace(-2.5, 2.5, 8)\n",
    "y_arr = np.linspace(-2.5, 2.5, 8)\n",
    "X_arr, Y_arr = np.meshgrid(x_arr, y_arr)\n",
    "U = 2 * X_arr  # ∂f/∂x = 2x\n",
    "V = 2 * Y_arr  # ∂f/∂y = 2y\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contour(X, Y, Z, levels=15, cmap='viridis')\n",
    "plt.colorbar(label='f(x,y) = x² + y²')\n",
    "plt.quiver(X_arr, Y_arr, U, V, color='red', alpha=0.7)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Paraboloïde: gradiënt wijst weg van minimum (0,0)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 5b - Zadelfunctie\n",
    "Z_saddle = X**2 - Y**2\n",
    "\n",
    "U_saddle = 2 * X_arr  # ∂f/∂x = 2x\n",
    "V_saddle = -2 * Y_arr  # ∂f/∂y = -2y\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contour(X, Y, Z_saddle, levels=15, cmap='RdBu')\n",
    "plt.colorbar(label='f(x,y) = x² - y²')\n",
    "plt.quiver(X_arr, Y_arr, U_saddle, V_saddle, color='green', alpha=0.7)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Zadelfunctie: (0,0) is geen minimum!', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Bij de zadelfunctie is (0,0) een zadelpunt:\")\n",
    "print(\"- Minimum in de x-richting\")\n",
    "print(\"- Maximum in de y-richting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 6: Afgeleide van Activatiefuncties - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 6a\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "def leaky_relu_prime(x, alpha=0.01):\n",
    "    return np.where(x > 0, 1, alpha)\n",
    "\n",
    "# Plot\n",
    "x_range = np.linspace(-4, 4, 200)\n",
    "\n",
    "activations = [\n",
    "    ('ReLU', relu, relu_prime),\n",
    "    ('Sigmoid', sigmoid, sigmoid_prime),\n",
    "    ('Tanh', tanh, tanh_prime),\n",
    "    ('Leaky ReLU', leaky_relu, leaky_relu_prime),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i, (name, f, f_prime) in enumerate(activations):\n",
    "    # Functie\n",
    "    axes[0, i].plot(x_range, f(x_range), 'b-', linewidth=2)\n",
    "    axes[0, i].set_title(name)\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    axes[0, i].axhline(y=0, color='k', linewidth=0.5)\n",
    "    axes[0, i].axvline(x=0, color='k', linewidth=0.5)\n",
    "    \n",
    "    # Afgeleide\n",
    "    axes[1, i].plot(x_range, f_prime(x_range), 'r-', linewidth=2)\n",
    "    axes[1, i].set_title(f\"{name}'\")\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "    axes[1, i].axhline(y=0, color='k', linewidth=0.5)\n",
    "    axes[1, i].axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 6b - Antwoord\n",
    "\n",
    "**Dead Neurons probleem:**\n",
    "- Bij ReLU is de afgeleide 0 voor x < 0\n",
    "- Als een neuron altijd negatieve inputs krijgt, wordt de gradiënt 0\n",
    "- Geen gradiënt = geen updates = neuron \"sterft\" en leert niet meer\n",
    "\n",
    "**Leaky ReLU oplossing:**\n",
    "- Heeft een kleine helling (0.01) voor x < 0\n",
    "- Er is altijd een kleine gradiënt, zelfs voor negatieve inputs\n",
    "- Neuronen kunnen \"herleven\" en blijven leren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 7: Neuron Afgeleiden - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 7a\n",
    "# y = σ(w₁x₁ + w₂x₂ + b)\n",
    "# z = w₁x₁ + w₂x₂ + b\n",
    "# y = σ(z)\n",
    "\n",
    "# σ'(z) = σ(z)(1-σ(z)) = y(1-y)\n",
    "# ∂y/∂w₁ = σ'(z) · x₁ = y(1-y) · x₁\n",
    "# ∂y/∂w₂ = σ'(z) · x₂ = y(1-y) · x₂\n",
    "# ∂y/∂b  = σ'(z) · 1  = y(1-y)\n",
    "# ∂y/∂x₁ = σ'(z) · w₁ = y(1-y) · w₁\n",
    "# ∂y/∂x₂ = σ'(z) · w₂ = y(1-y) · w₂\n",
    "\n",
    "def neuron_forward(x1, x2, w1, w2, b):\n",
    "    z = w1*x1 + w2*x2 + b\n",
    "    y = sigmoid(z)\n",
    "    return y, z\n",
    "\n",
    "def neuron_gradients(x1, x2, w1, w2, b):\n",
    "    y, z = neuron_forward(x1, x2, w1, w2, b)\n",
    "    dy_dz = y * (1 - y)\n",
    "    \n",
    "    return {\n",
    "        'dy_dw1': dy_dz * x1,\n",
    "        'dy_dw2': dy_dz * x2,\n",
    "        'dy_db': dy_dz,\n",
    "        'dy_dx1': dy_dz * w1,\n",
    "        'dy_dx2': dy_dz * w2,\n",
    "    }\n",
    "\n",
    "# Test\n",
    "x1, x2 = 2.0, 3.0\n",
    "w1, w2 = 0.5, -0.3\n",
    "b = 0.1\n",
    "\n",
    "y, z = neuron_forward(x1, x2, w1, w2, b)\n",
    "grads = neuron_gradients(x1, x2, w1, w2, b)\n",
    "\n",
    "print(f\"Input: x₁={x1}, x₂={x2}, w₁={w1}, w₂={w2}, b={b}\")\n",
    "print(f\"z = {z}, y = {y:.6f}\")\n",
    "print()\n",
    "print(\"Gradiënten (analytisch):\")\n",
    "for name, val in grads.items():\n",
    "    print(f\"  {name}: {val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerieke verificatie\n",
    "h = 1e-5\n",
    "\n",
    "def f_neuron(x1, x2, w1, w2, b):\n",
    "    return neuron_forward(x1, x2, w1, w2, b)[0]\n",
    "\n",
    "num_grads = {\n",
    "    'dy_dw1': (f_neuron(x1, x2, w1+h, w2, b) - f_neuron(x1, x2, w1, w2, b)) / h,\n",
    "    'dy_dw2': (f_neuron(x1, x2, w1, w2+h, b) - f_neuron(x1, x2, w1, w2, b)) / h,\n",
    "    'dy_db': (f_neuron(x1, x2, w1, w2, b+h) - f_neuron(x1, x2, w1, w2, b)) / h,\n",
    "    'dy_dx1': (f_neuron(x1+h, x2, w1, w2, b) - f_neuron(x1, x2, w1, w2, b)) / h,\n",
    "    'dy_dx2': (f_neuron(x1, x2+h, w1, w2, b) - f_neuron(x1, x2, w1, w2, b)) / h,\n",
    "}\n",
    "\n",
    "print(\"Verificatie:\")\n",
    "print(f\"{'Gradiënt':>10} | {'Analytisch':>12} | {'Numeriek':>12} | {'Match':>5}\")\n",
    "print(\"-\" * 50)\n",
    "for name in grads:\n",
    "    ana = grads[name]\n",
    "    num = num_grads[name]\n",
    "    match = \"✓\" if np.isclose(ana, num, rtol=1e-4) else \"✗\"\n",
    "    print(f\"{name:>10} | {ana:>12.6f} | {num:>12.6f} | {match:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 7b - ReLU neuron\n",
    "def relu_neuron_forward(x1, x2, w1, w2, b):\n",
    "    z = w1*x1 + w2*x2 + b\n",
    "    y = relu(z)\n",
    "    return y, z\n",
    "\n",
    "def relu_neuron_gradients(x1, x2, w1, w2, b):\n",
    "    y, z = relu_neuron_forward(x1, x2, w1, w2, b)\n",
    "    \n",
    "    # ReLU'(z) = 1 als z > 0, anders 0\n",
    "    dy_dz = 1.0 if z > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'dy_dw1': dy_dz * x1,\n",
    "        'dy_dw2': dy_dz * x2,\n",
    "        'dy_db': dy_dz,\n",
    "        'dy_dx1': dy_dz * w1,\n",
    "        'dy_dx2': dy_dz * w2,\n",
    "        'z': z,\n",
    "        'active': z > 0\n",
    "    }\n",
    "\n",
    "# Test met positieve z\n",
    "print(\"Test 1: z > 0 (neuron actief)\")\n",
    "grads1 = relu_neuron_gradients(2, 3, 0.5, 0.3, 0.1)\n",
    "print(f\"z = {grads1['z']}, actief: {grads1['active']}\")\n",
    "print(f\"Gradiënten: dy_dw1={grads1['dy_dw1']}, dy_dw2={grads1['dy_dw2']}\")\n",
    "print()\n",
    "\n",
    "# Test met negatieve z\n",
    "print(\"Test 2: z < 0 (neuron inactief)\")\n",
    "grads2 = relu_neuron_gradients(2, 3, -0.5, -0.3, -2)\n",
    "print(f\"z = {grads2['z']}, actief: {grads2['active']}\")\n",
    "print(f\"Gradiënten: dy_dw1={grads2['dy_dw1']}, dy_dw2={grads2['dy_dw2']}\")\n",
    "print()\n",
    "print(\"Als z < 0: alle gradiënten zijn 0 - het neuron leert niet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 8: Kettingregel in Actie - Oplossingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht 8a & 8b\n",
    "# Mini-netwerk:\n",
    "# h = σ(w₁x + b₁)\n",
    "# y = σ(w₂h + b₂)\n",
    "\n",
    "# ∂y/∂w₁ = ∂y/∂h · ∂h/∂w₁\n",
    "#        = [σ'(w₂h + b₂) · w₂] · [σ'(w₁x + b₁) · x]\n",
    "\n",
    "def mini_network(x, w1, b1, w2, b2):\n",
    "    \"\"\"Forward pass.\"\"\"\n",
    "    z1 = w1 * x + b1\n",
    "    h = sigmoid(z1)\n",
    "    z2 = w2 * h + b2\n",
    "    y = sigmoid(z2)\n",
    "    return y, h, z1, z2\n",
    "\n",
    "def mini_network_gradients(x, w1, b1, w2, b2):\n",
    "    \"\"\"Backward pass - alle gradiënten.\"\"\"\n",
    "    # Forward\n",
    "    y, h, z1, z2 = mini_network(x, w1, b1, w2, b2)\n",
    "    \n",
    "    # Backward: start bij output\n",
    "    dy_dz2 = y * (1 - y)  # σ'(z2)\n",
    "    \n",
    "    # Gradiënten voor laag 2\n",
    "    dy_dw2 = dy_dz2 * h\n",
    "    dy_db2 = dy_dz2 * 1\n",
    "    dy_dh = dy_dz2 * w2\n",
    "    \n",
    "    # Terug naar laag 1\n",
    "    dh_dz1 = h * (1 - h)  # σ'(z1)\n",
    "    \n",
    "    # Gradiënten voor laag 1 (kettingregel!)\n",
    "    dy_dz1 = dy_dh * dh_dz1\n",
    "    dy_dw1 = dy_dz1 * x\n",
    "    dy_db1 = dy_dz1 * 1\n",
    "    \n",
    "    return {\n",
    "        'dy_dw2': dy_dw2,\n",
    "        'dy_db2': dy_db2,\n",
    "        'dy_dw1': dy_dw1,\n",
    "        'dy_db1': dy_db1,\n",
    "        'y': y,\n",
    "        'h': h\n",
    "    }\n",
    "\n",
    "# Test\n",
    "x = 2.0\n",
    "w1, b1 = 0.5, -0.2\n",
    "w2, b2 = 0.8, 0.1\n",
    "\n",
    "grads = mini_network_gradients(x, w1, b1, w2, b2)\n",
    "\n",
    "print(\"Mini-netwerk: h = σ(w₁x + b₁), y = σ(w₂h + b₂)\")\n",
    "print(f\"\\nInput: x={x}, w₁={w1}, b₁={b1}, w₂={w2}, b₂={b2}\")\n",
    "print(f\"Hidden: h = {grads['h']:.6f}\")\n",
    "print(f\"Output: y = {grads['y']:.6f}\")\n",
    "print()\n",
    "print(\"Gradiënten (analytisch):\")\n",
    "print(f\"  ∂y/∂w₂ = {grads['dy_dw2']:.6f}\")\n",
    "print(f\"  ∂y/∂b₂ = {grads['dy_db2']:.6f}\")\n",
    "print(f\"  ∂y/∂w₁ = {grads['dy_dw1']:.6f}\")\n",
    "print(f\"  ∂y/∂b₁ = {grads['dy_db1']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerieke verificatie\n",
    "h = 1e-5\n",
    "\n",
    "def f_net(x, w1, b1, w2, b2):\n",
    "    return mini_network(x, w1, b1, w2, b2)[0]\n",
    "\n",
    "num_grads = {\n",
    "    'dy_dw2': (f_net(x, w1, b1, w2+h, b2) - f_net(x, w1, b1, w2, b2)) / h,\n",
    "    'dy_db2': (f_net(x, w1, b1, w2, b2+h) - f_net(x, w1, b1, w2, b2)) / h,\n",
    "    'dy_dw1': (f_net(x, w1+h, b1, w2, b2) - f_net(x, w1, b1, w2, b2)) / h,\n",
    "    'dy_db1': (f_net(x, w1, b1+h, w2, b2) - f_net(x, w1, b1, w2, b2)) / h,\n",
    "}\n",
    "\n",
    "print(\"Verificatie:\")\n",
    "print(f\"{'Gradiënt':>10} | {'Analytisch':>12} | {'Numeriek':>12} | {'Match':>5}\")\n",
    "print(\"-\" * 50)\n",
    "for name in ['dy_dw2', 'dy_db2', 'dy_dw1', 'dy_db1']:\n",
    "    ana = grads[name]\n",
    "    num = num_grads[name]\n",
    "    match = \"✓\" if np.isclose(ana, num, rtol=1e-4) else \"✗\"\n",
    "    print(f\"{name:>10} | {ana:>12.6f} | {num:>12.6f} | {match:>5}\")\n",
    "\n",
    "print()\n",
    "print(\"Dit is de essentie van backpropagation: de kettingregel\")\n",
    "print(\"automatisch door meerdere lagen toepassen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Mathematical Foundations** | Les 5 Oplossingen | IT & Artificial Intelligence\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
