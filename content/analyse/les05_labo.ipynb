{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 5: Labo - Oefeningen\n",
    "\n",
    "**Mathematical Foundations - IT & Artificial Intelligence**\n",
    "\n",
    "---\n",
    "\n",
    "In dit labo oefen je met afgeleiden, de kettingregel en partiële afgeleiden. Dit vormt de basis voor het begrijpen van hoe neurale netwerken leren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print(\"Libraries geladen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 1: Numerieke Afgeleiden\n",
    "\n",
    "*Geschatte tijd: 15 minuten*\n",
    "\n",
    "### Opdracht 1a\n",
    "\n",
    "Implementeer een functie `numerical_derivative(f, x, h=1e-5)` die de afgeleide van f op punt x numeriek benadert met de forward difference methode: (f(x+h) - f(x)) / h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 1a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 1b\n",
    "\n",
    "Test je functie op f(x) = x³ op het punt x = 2. De analytische afgeleide is f'(x) = 3x², dus f'(2) = 12.\n",
    "\n",
    "Experimenteer met verschillende waarden van h: 1, 0.1, 0.01, 0.001, 1e-5, 1e-8, 1e-12. Wat valt je op?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 1b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 1c\n",
    "\n",
    "Implementeer ook de central difference methode: (f(x+h) - f(x-h)) / (2h). Vergelijk de nauwkeurigheid met de forward difference methode voor dezelfde h-waarden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 1c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 2: Basisregels Oefenen\n",
    "\n",
    "*Geschatte tijd: 20 minuten*\n",
    "\n",
    "### Opdracht 2a\n",
    "\n",
    "Bereken de afgeleide analytisch (met de hand) voor de volgende functies:\n",
    "\n",
    "1. f(x) = 5x⁴\n",
    "2. g(x) = x³ - 2x² + 4x - 1\n",
    "3. h(x) = 3/x (hint: schrijf als 3x⁻¹)\n",
    "4. k(x) = √x (hint: schrijf als x^(1/2))\n",
    "5. m(x) = 2eˣ + 3x²\n",
    "\n",
    "Implementeer dan zowel de originele functies als hun afgeleiden in Python en verifieer met numerieke afgeleiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 2a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 2b\n",
    "\n",
    "Plot de functie f(x) = x³ - 3x + 1 en zijn afgeleide f'(x) = 3x² - 3 op hetzelfde figuur voor x ∈ [-3, 3]. \n",
    "\n",
    "Waar is f'(x) = 0? Wat betekent dit voor f(x)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 2b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 3: De Kettingregel\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 3a\n",
    "\n",
    "Bereken de afgeleide met de kettingregel voor:\n",
    "\n",
    "1. f(x) = (2x + 1)³\n",
    "2. g(x) = e^(x²)\n",
    "3. h(x) = sin(3x) (afgeleide van sin is cos)\n",
    "4. k(x) = √(x² + 1)\n",
    "\n",
    "Implementeer de functies en hun afgeleiden, en verifieer numeriek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 3a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 3b\n",
    "\n",
    "Beschouw de functie f(x) = σ(2x - 1) waarbij σ de sigmoid functie is.\n",
    "\n",
    "1. Bereken f'(x) met de kettingregel\n",
    "2. Implementeer f(x) en f'(x)\n",
    "3. Plot beide functies\n",
    "4. Verifieer numeriek op x = 0, 0.5, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Jouw code voor opdracht 3b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 3c\n",
    "\n",
    "Dubbele kettingregel: bereken de afgeleide van f(x) = e^(sin(x²)).\n",
    "\n",
    "Hint: dit is f(g(h(x))) met h(x) = x², g(u) = sin(u), f(v) = eᵛ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 3c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 4: Partiële Afgeleiden\n",
    "\n",
    "*Geschatte tijd: 20 minuten*\n",
    "\n",
    "### Opdracht 4a\n",
    "\n",
    "Bereken de partiële afgeleiden ∂f/∂x en ∂f/∂y voor:\n",
    "\n",
    "1. f(x, y) = x² + y²\n",
    "2. f(x, y) = 3xy + x - 2y\n",
    "3. f(x, y) = e^(xy)\n",
    "4. f(x, y) = x²y³\n",
    "\n",
    "Implementeer en verifieer numeriek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerieke partiële afgeleiden helper\n",
    "def numerical_partial_x(f, x, y, h=1e-5):\n",
    "    return (f(x + h, y) - f(x, y)) / h\n",
    "\n",
    "def numerical_partial_y(f, x, y, h=1e-5):\n",
    "    return (f(x, y + h) - f(x, y)) / h\n",
    "\n",
    "# Jouw code voor opdracht 4a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 4b\n",
    "\n",
    "Gegeven f(x, y, z) = x²y + yz² + xz, bereken alle drie de partiële afgeleiden en de gradiënt ∇f. Evalueer op het punt (1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 4b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 5: Gradiënt Visualiseren\n",
    "\n",
    "*Geschatte tijd: 15 minuten*\n",
    "\n",
    "### Opdracht 5a\n",
    "\n",
    "Maak een contourplot van f(x, y) = x² + y² (een paraboloïde) en teken gradiëntvectoren als pijlen. De gradiënt is ∇f = [2x, 2y]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 5a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 5b\n",
    "\n",
    "Doe hetzelfde voor de \"zadel\" functie f(x, y) = x² - y². Merk op hoe de gradiënten zich anders gedragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 5b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 6: Afgeleide van Activatiefuncties\n",
    "\n",
    "*Geschatte tijd: 20 minuten*\n",
    "\n",
    "### Opdracht 6a\n",
    "\n",
    "Implementeer de volgende activatiefuncties en hun afgeleiden:\n",
    "\n",
    "1. **ReLU:** f(x) = max(0, x)\n",
    "2. **Sigmoid:** σ(x) = 1/(1 + e^(-x)), afgeleide: σ'(x) = σ(x)(1 - σ(x))\n",
    "3. **Tanh:** tanh(x) = (e^x - e^(-x))/(e^x + e^(-x)), afgeleide: tanh'(x) = 1 - tanh²(x)\n",
    "4. **Leaky ReLU:** f(x) = x als x > 0, anders 0.01x\n",
    "\n",
    "Plot elke functie samen met zijn afgeleide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 6a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 6b\n",
    "\n",
    "De afgeleide van ReLU is 0 voor x < 0. Leg uit waarom dit een probleem kan zijn voor neurale netwerken (\"dead neurons\"). Hoe lost Leaky ReLU dit op?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jouw antwoord:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 7: Neuron Afgeleiden\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 7a\n",
    "\n",
    "Beschouw een neuron met meerdere inputs: y = σ(w₁x₁ + w₂x₂ + b).\n",
    "\n",
    "Bereken analytisch:\n",
    "- ∂y/∂w₁\n",
    "- ∂y/∂w₂\n",
    "- ∂y/∂b\n",
    "- ∂y/∂x₁\n",
    "- ∂y/∂x₂\n",
    "\n",
    "Implementeer een functie die al deze gradiënten berekent en verifieer numeriek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 7a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 7b\n",
    "\n",
    "Breid uit naar een neuron met ReLU activatie: y = ReLU(w₁x₁ + w₂x₂ + b).\n",
    "\n",
    "Bereken de gradiënten en merk op dat ze afhankelijk zijn van het teken van de input naar ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 7b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oefening 8: Kettingregel in Actie\n",
    "\n",
    "*Geschatte tijd: 25 minuten*\n",
    "\n",
    "### Opdracht 8a\n",
    "\n",
    "Beschouw een mini-netwerk met twee neuronen in serie:\n",
    "\n",
    "h = σ(w₁x + b₁)  (hidden neuron)\n",
    "\n",
    "y = σ(w₂h + b₂)  (output neuron)\n",
    "\n",
    "Bereken ∂y/∂w₁ met de kettingregel. Je zult merken dat dit afhangt van ∂y/∂h en ∂h/∂w₁."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 8a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opdracht 8b\n",
    "\n",
    "Implementeer het mini-netwerk en bereken alle gradiënten:\n",
    "- ∂y/∂w₂, ∂y/∂b₂\n",
    "- ∂y/∂w₁, ∂y/∂b₁\n",
    "\n",
    "Verifieer numeriek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor opdracht 8b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonusoefening: Automatische Differentiatie\n",
    "\n",
    "*Geschatte tijd: 30 minuten*\n",
    "\n",
    "### Bonus\n",
    "\n",
    "Implementeer een eenvoudige vorm van automatische differentiatie. Maak een `Value` class die:\n",
    "\n",
    "1. Een waarde opslaat\n",
    "2. Basis operaties ondersteunt (+, *, **)\n",
    "3. De afgeleide automatisch bijhoudt via de kettingregel\n",
    "\n",
    "Hint: elke operatie moet weten hoe hij zijn lokale gradiënt berekent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jouw code voor de bonusoefening:\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        # ...\n",
    "    \n",
    "    # Implementeer __add__, __mul__, __pow__, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Klaar!\n",
    "\n",
    "Je hebt de labo-oefeningen van les 5 afgerond. Je begrijpt nu afgeleiden, de kettingregel en partiële afgeleiden - de bouwstenen voor het trainen van neurale netwerken.\n",
    "\n",
    "In de volgende les leren we gradient descent: hoe we de gradiënt gebruiken om parameters te optimaliseren.\n",
    "\n",
    "---\n",
    "\n",
    "**Mathematical Foundations** | Les 5 Labo | IT & Artificial Intelligence\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
